import pandas as pd
import numpy as np


df = pd.read_csv("housing.csv")


df["income_cat"] = pd.cut(df["median_income"] , bins =[ 0 , 1.5 ,3.0 ,4.5 , 6.0 , np.inf] , labels = [1 , 2, 3, 4 , 5])


from sklearn.model_selection import StratifiedShuffleSplit
split = StratifiedShuffleSplit(n_splits = 1 , test_size = 0.2 , random_state = 42)
for train_index , test_index in split.split(df, df["income_cat"]):
    train_data = df.loc[train_index]
    test_data = df.loc[test_index]


#Removing income_cat
for sett in (train_data , test_data):
    sett.drop("income_cat" , axis = 1 , inplace = True)


df = train_data.copy()


df.head()


housing = df.drop("median_house_value" , axis = 1)
housing_labels = train_data["median_house_value"].copy


housing


from sklearn.impute import SimpleImputer


imputer = SimpleImputer(strategy="median")
housing_num = housing.select_dtypes(include=[np.number])
imputer.fit(housing_num)


X = imputer.transform(housing_num)


X


housing = pd.DataFrame(X , columns = housing_num.columns , index = housing_num.index)


housing


housing.info()


housing["ocean_proximity"] = df["ocean_proximity"]


housing


housing_cat = housing[["ocean_proximity"]]


housing_cat


from sklearn.preprocessing import OrdinalEncoder
oridinal_encoder = OrdinalEncoder()
housing_cat_encoded = oridinal_encoder.fit_transform(housing)


housing_cat_encoded


housing_cat_encoded = pd.DataFrame(housing_cat_encoded , columns= housing.columns , index = housing.index)


housing_cat_encoded


from sklearn.preprocessing import OneHotEncoder
one_hot_encoder = OneHotEncoder()
housing_cat_encoded =  one_hot_encoder.fit_transform(housing_cat)


one_hot_encoder.categories_


housing_cat_encoded = pd.DataFrame(housing_cat_encoded.toarray() , columns = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']  , index= housing_cat.index)


housing_cat_encoded


housing_con = pd.concat([housing , housing_cat_encoded] , axis = 1)


housing_con


if 'ocean_proximity' in housing_con.columns:
    housing_con.drop('ocean_proximity', axis=1, inplace=True)
    print("Column dropped successfully!")
else:
    print("Column already deleted or not found.")


#FEATURE SCALING = HAR EK COLUMNS KA RANGE EK HI RAHE ISLIYE KAR RHE HAI


from sklearn.preprocessing import MinMaxScaler
min_max_scale = MinMaxScaler(feature_range=(-1 , 1))
housing_scaled = min_max_scale.fit_transform(housing_con)


housing_scaled


housing_scaled = pd.DataFrame(housing_scaled , columns = housing_con.columns , index = housing_con.index)


housing_scaled


from sklearn.preprocessing import StandardScaler
standard_scaler  = StandardScaler()
housing_scaledd = standard_scaler.fit_transform(housing_con)


housing_scaledd = pd.DataFrame(housing_scaledd , columns = housing_con.columns , index = housing_con.index )


housing_scaledd



